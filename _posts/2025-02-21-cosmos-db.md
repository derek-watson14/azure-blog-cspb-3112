---
layout: post
title: "Develop solutions that use Azure Cosmos DB"
date: 2025-02-21
---

**Learning path link: [AZ-204: Develop solutions that use Azure Cosmos DB](https://learn.microsoft.com/en-us/training/paths/az-204-develop-solutions-that-use-azure-cosmos-db/)**

*Methodology: For each learning objective in each module, write a short summary demonstrating knowledge matching the objective as learned in the course.*

## Post-course review

I do not normally work with NoSQL databases so I wasnt particularly familiar with this technology. I also read that this is not covered thoroughly on the test so I decided against completing the practical module of this learning path for the sake of time. I learned about the benefits of this service and how cheap, fast and scalable it can be if a service can be served by a NoSQL database. The section about different consistency levels was interesting as well as the part about request units. Overall, this was not the most engaging learning path for me because I cannot conceieve of a scenario in which I would actually use Cosmos DB in my organization. Nonetheless, it is good to know that it exists when considering how to solve new problems in the future.

*Course notes by module start below*

<hr/>

## Module 1: Explore Azure Cosmos DB

#### Learning Objectives

- Identify the key benefits provided by Azure Cosmos DB
- Describe the elements in an Azure Cosmos DB account and how they're organized
- Explain the different consistency levels and choose the correct one for your project
- Explore the APIs supported in Azure Cosmos DB and choose the appropriate API for your solution
- Describe how request units impact costs

### Key Benefits
- Fully managed NoSQL database
- Low latency
- Elastic scalability of throughput
- "Well defined semantics for data consistency"
- High availability
- Can be globally distributed in any Azure region 
- Add regions any time w/o downtime
- "Multi-master" replication protocol for read/write
- Unlimited read/write scalability
- 99.999% r/w availability around world
- Guaranteed reads and writes served in less than 10ms at the 99th percentile

Application can perform near real-time reads and writes against all the regions you chose for your database. Handles data replication between regions at consistency level selected. Fallover to other regions is automatic.

### Elements of Cosmos DB account and organization
- Cosmos DB account has unique DNS name and can be managed with CLI, Portal or SDKs
- Database Account -> Databases -> Container(s) -> Item
- A container is fundamental unit of scalability
- Unlimited throguhput (RU/s) and storage on a container
- Containers are transparently partitioned with local partition key you specify for elastic scaling
- 50 Accounts/Azure Subscription

Database is analagous to a namespace, and is a unit of management for a set of containers.

Container is where data is stored. Scaling is horizontal. Stored in multiple servers called partitions, increasing partitions increases throughput. For each container a partition key must be supplied. The partition key is a property selected on items so data is distributed efficiently. The key is used to route data to the correct partition, can also be used in WHERE clauses.

> The underlying storage mechanism for data in Azure Cosmos DB is called a physical partition. Physical partitions can have a throughput amount up to 10,000 Request Units per second, and they can store up to 50 GB of data. Azure Cosmos DB abstracts this partitioning concept with a logical partition, which can store up to 20 GB of data.

Throughput is configured either:
- Dedicated throughput: TP exclusively reserved for a container, standard and autoscale
- Shared: Specified at database level and shared with up to 25 containers within the database. Excludes containers with dedicated TP

Item names by DB type: 
NoSQL: Item, Cassandra: Row, MongoDB: Document, Gremlin: Node or edge, Table: Item

**Consistency levels |** Spectrum of choices, from strong to eventual consistency. Below illustrates the 5 well-defined levels:

![5-consistency-levels](/assets/images/five-consistency-levels.png)

Consistency levels are guaranteed for all operations regardless of request region, number of regions, account write region configuration. Each has a comprehensive SLA. Set a default level on the account. Read consistency is scoped to one read op in a logical partition.

**Strong |** The reads are guaranteed to return the most recent committed version of an item. A client never sees an uncommitted or partial write. Users are always guaranteed to read the latest committed write.

> For all consistency levels weaker than Strong, writes are replicated to a minimum of three replicas (in a four replica set) in the local region, with asynchronous replication to all other regions.

**Bounded staleness |** Lag of data between any two regions is always less than a specified amount. The amount can be K versions (that is, updates) of an item or by T time intervals, whichever is reached first. Beneficial primarily to single-region write accounts with two or more regions. If the staleness value is exceeed in a partition, writes are throttled.

**Session |** Reads are guaranteed to honor the read-your-writes, and write-follows-reads guarantees, assuming a single session token. 

**Consistent prefix |** Updates made as single document writes see eventual consistency, write operations within a transaction of multiple documents are always visible together.

**Eventual |** No ordering guarantee for reads. In the absence of any further writes, the replicas eventually converge. Ideal where the application doesn't require any ordering guarantees. Examples include count of Retweets, Likes, or nonthreaded comments.


### Supported APIs

NoSQL, MongoDB, PostgreSQL, Cassandra, Gremlin, and Table are the available APIs. Can be used to model real world data using documents, key-value, graph, and column-family data models. All over automatic scaling and performance guarantees. API for NoSQL is native to Azure Cosmos DB. MongoDB, PostgreSQL, Cassandra, Gremlin, and Table implement the wire protocol of open-source database engines, are good if you have an existing implementation or like open-source.

> These APIs allow your applications to treat Azure Cosmos DB as if it were various other databases technologies, without the overhead of management, and scaling approaches.

**API** | Description
-------| ----------------
**NoSQL** | Document format, best E2E experience, always gets new features first, supports SQL syntax.
**MongoDB** | Document format (BSON), doenst use native MongoDB code but compatible with wire protocol.
**PostgreSQL** | Citus open source distributed tables, data in single node or multi-node config.
**Cassandra** | Column oriented schema. Distributed, horizontal scaling approach with flexibility of column orientation. 
**Gremlin** | Edges and vertices. Graph queries possible. Good for dynamic data, complex relations, models too complex for relational.
**Table** | Key/value format. Only supports OLTP (Online Transaction Processing). Improves over Azure Table storage for latency, scaling, throughput, distribution, index management, etc.

### Request Units and Costs

> You pay for the throughput you provision and the storage you consume on an hourly basis.

Throughput must be provisioned to unsyre sufficient resources always. **Request units** are RUs and are how db operations are normalized. An RU represents CPU, IOPS and memory to perform the operation. This is true for all APIs

> The cost to do a point read, which is fetching a single item by its ID and partition key value, for a 1-KB item is 1RU.

![request-units](/assets/images/request-units.png)

How you are charged is based on the type of account:

- Provisioned: Provision number of RUs on per-second basis incremented by 100 RUs. Provisioned at container or database granularity.
- Serverless: No provisioning. Simply get billed for number of RUs consumed. Only single region.
- Autoscale: Automatically and instantly scale the throughput (RU/s) of your database or container based on its usage. Well suited for workloads that have variable or unpredictable traffic patterns.

<br/>